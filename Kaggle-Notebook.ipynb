{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition: Pet Adoption\n",
    "\n",
    "`source`: https://www.kaggle.com/c/petfinder-adoption-prediction/\n",
    "\n",
    "## Description\n",
    "Millions of stray animals suffer on the streets or are euthanized in shelters every day around the world. If homes can be found for them, many precious lives can be saved — and more happy families created.\n",
    "\n",
    "[PetFinder.my](https://petfinder.my/) has been Malaysia’s leading animal welfare platform since 2008, with a database of more than 150,000 animals. PetFinder collaborates closely with animal lovers, media, corporations, and global organizations to improve animal welfare.\n",
    "\n",
    "Animal adoption rates are strongly correlated to the metadata associated with their online profiles, such as descriptive text and photo characteristics. As one example, PetFinder is currently experimenting with a simple AI tool called the Cuteness Meter, which ranks how cute a pet is based on qualities present in their photos.\n",
    "\n",
    "In this competition you will be developing algorithms to predict the adoptability of pets - specifically, how quickly is a pet adopted? If successful, they will be adapted into AI tools that will guide shelters and rescuers around the world on improving their pet profiles' appeal, reducing animal suffering and euthanization.\n",
    "\n",
    "Top participants may be invited to collaborate on implementing their solutions into AI tools for assessing and improving pet adoption performance, which will benefit global animal welfare.\n",
    "\n",
    "### Data Description\n",
    "In this competition you will predict the speed at which a pet is adopted, based on the pet’s listing on PetFinder. Sometimes a profile represents a group of pets. In this case, the speed of adoption is determined by the speed at which all of the pets are adopted. The data included text, tabular, and image data. See below for details. \n",
    "This is a Kernels-only competition. At the end of the competition, test data will be replaced in their entirety with new data of approximately the same size, and your kernels will be rerun on the new data.\n",
    "\n",
    "#### File descriptions\n",
    "* `train.csv` - Tabular/text data for the training set\n",
    "* `test.csv` - Tabular/text data for the test set\n",
    "* `sample_submission.csv` - A sample submission file in the correct format\n",
    "* `breed_labels.csv` - Contains Type, and BreedName for each BreedID. Type $1$ is dog, $2$ is cat.\n",
    "* `color_labels.csv` - Contains ColorName for each ColorID\n",
    "* `state_labels.csv` - Contains StateName for each StateID\n",
    "\n",
    "#### Data Fields\n",
    "* `PetID` - Unique hash ID of pet profile\n",
    "* `AdoptionSpeed` - Categorical speed of adoption. Lower is faster. This is the value to predict. See below section for more info.\n",
    "* `Type` - Type of animal ($1$ = Dog, $2$ = Cat)\n",
    "* `Name` - Name of pet (Empty if not named)\n",
    "* `Age` - Age of pet when listed, in months\n",
    "* `Breed1` - Primary breed of pet (Refer to BreedLabels dictionary)\n",
    "* `Breed2` - Secondary breed of pet, if pet is of mixed breed (Refer to BreedLabels dictionary)\n",
    "* `Gender` - Gender of pet ($1$ = Male, $2$ = Female, $3$ = Mixed, if profile represents group of pets)\n",
    "* `Color1` - Color 1 of pet (Refer to ColorLabels dictionary)\n",
    "* `Color2` - Color 2 of pet (Refer to ColorLabels dictionary)\n",
    "* `Color3` - Color 3 of pet (Refer to ColorLabels dictionary)\n",
    "* `MaturitySize` - Size at maturity ($1$ = Small, $2$ = Medium, $3$ = Large, $4$ = Extra Large, $0$ = Not Specified)\n",
    "* `FurLength` - Fur length ($1$ = Short, $2$ = Medium, $3$ = Long, $0$ = Not Specified)\n",
    "* `Vaccinated` - Pet has been vaccinated ($1$ = Yes, $2$ = No, $3$ = Not Sure)\n",
    "* `Dewormed` - Pet has been dewormed ($1$ = Yes, $2$ = No, $3$ = Not Sure)\n",
    "* `Sterilized` - Pet has been spayed / neutered ($1$ = Yes, $2$ = No, $3$ = Not Sure)\n",
    "* `Health` - Health Condition ($1$ = Healthy, $2$ = Minor Injury, $3$ = Serious Injury, $0$ = Not Specified)\n",
    "* `Quantity` - Number of pets represented in profile\n",
    "* `Fee` - Adoption fee ($0$ = Free)\n",
    "* `State` - State location in Malaysia (Refer to StateLabels dictionary)\n",
    "* `RescuerID` - Unique hash ID of rescuer\n",
    "* `VideoAmt` - Total uploaded videos for this pet\n",
    "* `PhotoAmt` - Total uploaded photos for this pet\n",
    "* `Description` - Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese.\n",
    "\n",
    "#### AdoptionSpeed\n",
    "Contestants are required to predict this value. The value is determined by how quickly, if at all, a pet is adopted. The values are determined in the following way:\n",
    "* $0$ - Pet was adopted on the same day as it was listed. \n",
    "* $1$ - Pet was adopted between 1 and 7 days (1st week) after being listed. \n",
    "* $2$ - Pet was adopted between 8 and 30 days (1st month) after being listed. \n",
    "* $3$ - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed. \n",
    "* $4$ - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days).\n",
    "\n",
    "#### Images\n",
    "For pets that have photos, they will be named in the format of *`PetID-ImageNumber.jpg`*. Image $1$ is the profile (`default`) photo set for the pet. For privacy purposes, faces, phone numbers and emails have been masked.\n",
    "\n",
    "#### Image Metadata\n",
    "We have run the images through **`Google's Vision API`**, providing analysis on `Face Annotation`, `Label Annotation`, `Text Annotation` and `Image Properties`. You may optionally utilize this supplementary information for your image analysis.\n",
    "\n",
    "File name format is *`PetID-ImageNumber.json`*.\n",
    "\n",
    "Some properties will not exist in JSON file if not present, i.e. Face Annotation. Text Annotation has been simplified to just 1 entry of the entire text description (instead of the detailed JSON result broken down by individual characters and words). Phone numbers and emails are already anonymized in Text Annotation.\n",
    "\n",
    "Google Vision API reference: https://cloud.google.com/vision/docs/reference/rest/v1/images/annotate\n",
    "\n",
    "#### Sentiment Data\n",
    "We have run each pet profile's description through **`Google's Natural Language API`**, providing analysis on sentiment and key entities. You may optionally utilize this supplementary information for your pet description analysis. There are some descriptions that the API could not analyze. As such, there are fewer sentiment files than there are rows in the dataset.\n",
    "\n",
    "File name format is *`PetID.json`*.\n",
    "\n",
    "Google Natural Language API reference: https://cloud.google.com/natural-language/docs/basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Pet Adoption Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Loading the data/train/train.csv\n",
    "df = pd.read_csv('./data/train/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the missing values\n",
    "\n",
    "It is very common to observe that the real-world datasets often have missing values due to myriad number of reasons.\n",
    "\n",
    "Missing values are not ideal for any Machine Learning algorithm to optimally decipher the patterns in the data\n",
    "\n",
    "Using the below code, we can find that `Name` column has $1257$ missing values and `Description` column has $12$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type                0\n",
       "Name             1257\n",
       "Age                 0\n",
       "Breed1              0\n",
       "Breed2              0\n",
       "Gender              0\n",
       "Color1              0\n",
       "Color2              0\n",
       "Color3              0\n",
       "MaturitySize        0\n",
       "FurLength           0\n",
       "Vaccinated          0\n",
       "Dewormed            0\n",
       "Sterilized          0\n",
       "Health              0\n",
       "Quantity            0\n",
       "Fee                 0\n",
       "State               0\n",
       "RescuerID           0\n",
       "VideoAmt            0\n",
       "Description        12\n",
       "PetID               0\n",
       "PhotoAmt            0\n",
       "AdoptionSpeed       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding out the missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Irrelevant  Columns\n",
    "\n",
    "* `Name`, `PetID`, `RescuerID`\n",
    "    * It makes sense to not have `Name` column because it does not help us predict how faster a pet animal will be adopted as we know that any prospective pet owner will not adopt a pet animal based on its name.\n",
    "    * Likewise `PetID`, `RescuerID` also have no relevance to the task at hand\n",
    "* However, for now to simplify the modeling let's ignore the following columns\n",
    "    * `Fee` - Might have some implication if a pet will adopted (Need to check the correlation)\n",
    "    * `State` - Might not influence the adoption speed (Need to check the correlation)\n",
    "    * `VideoAmt`, `PhotoAmt` & `Description` - Will have some impact on the adoption speed. Because a beautiful looking pet might get adopted sooner. But just to make the modeling simpler let's ignore it these columns as well for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the name column\n",
    "df = df.drop(labels=['Name', 'PetID', 'Fee', 'State', 'RescuerID', 'VideoAmt', 'PhotoAmt', 'Description'], \n",
    "             axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Age` column is in months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Months to Years\n",
    "df['Age'] /= 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Descriptive Statistics\n",
    "\n",
    "Taking a look at the descriptive statistics often helps us understand the data in each column quicker. And, very often we can find out the abnormal data in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "      <td>14993.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.457614</td>\n",
       "      <td>0.871006</td>\n",
       "      <td>265.272594</td>\n",
       "      <td>74.009738</td>\n",
       "      <td>1.776162</td>\n",
       "      <td>2.234176</td>\n",
       "      <td>3.222837</td>\n",
       "      <td>1.882012</td>\n",
       "      <td>1.862002</td>\n",
       "      <td>1.467485</td>\n",
       "      <td>1.731208</td>\n",
       "      <td>1.558727</td>\n",
       "      <td>1.914227</td>\n",
       "      <td>1.036617</td>\n",
       "      <td>1.576069</td>\n",
       "      <td>2.516441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498217</td>\n",
       "      <td>1.512983</td>\n",
       "      <td>60.056818</td>\n",
       "      <td>123.011575</td>\n",
       "      <td>0.681592</td>\n",
       "      <td>1.745225</td>\n",
       "      <td>2.742562</td>\n",
       "      <td>2.984086</td>\n",
       "      <td>0.547959</td>\n",
       "      <td>0.599070</td>\n",
       "      <td>0.667649</td>\n",
       "      <td>0.695817</td>\n",
       "      <td>0.566172</td>\n",
       "      <td>0.199535</td>\n",
       "      <td>1.472477</td>\n",
       "      <td>1.177265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type           Age        Breed1        Breed2        Gender  \\\n",
       "count  14993.000000  14993.000000  14993.000000  14993.000000  14993.000000   \n",
       "mean       1.457614      0.871006    265.272594     74.009738      1.776162   \n",
       "std        0.498217      1.512983     60.056818    123.011575      0.681592   \n",
       "min        1.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "25%        1.000000      0.166667    265.000000      0.000000      1.000000   \n",
       "50%        1.000000      0.250000    266.000000      0.000000      2.000000   \n",
       "75%        2.000000      1.000000    307.000000    179.000000      2.000000   \n",
       "max        2.000000     21.250000    307.000000    307.000000      3.000000   \n",
       "\n",
       "             Color1        Color2        Color3  MaturitySize     FurLength  \\\n",
       "count  14993.000000  14993.000000  14993.000000  14993.000000  14993.000000   \n",
       "mean       2.234176      3.222837      1.882012      1.862002      1.467485   \n",
       "std        1.745225      2.742562      2.984086      0.547959      0.599070   \n",
       "min        1.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "25%        1.000000      0.000000      0.000000      2.000000      1.000000   \n",
       "50%        2.000000      2.000000      0.000000      2.000000      1.000000   \n",
       "75%        3.000000      6.000000      5.000000      2.000000      2.000000   \n",
       "max        7.000000      7.000000      7.000000      4.000000      3.000000   \n",
       "\n",
       "         Vaccinated      Dewormed    Sterilized        Health      Quantity  \\\n",
       "count  14993.000000  14993.000000  14993.000000  14993.000000  14993.000000   \n",
       "mean       1.731208      1.558727      1.914227      1.036617      1.576069   \n",
       "std        0.667649      0.695817      0.566172      0.199535      1.472477   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        1.000000      1.000000      2.000000      1.000000      1.000000   \n",
       "50%        2.000000      1.000000      2.000000      1.000000      1.000000   \n",
       "75%        2.000000      2.000000      2.000000      1.000000      1.000000   \n",
       "max        3.000000      3.000000      3.000000      3.000000     20.000000   \n",
       "\n",
       "       AdoptionSpeed  \n",
       "count   14993.000000  \n",
       "mean        2.516441  \n",
       "std         1.177265  \n",
       "min         0.000000  \n",
       "25%         2.000000  \n",
       "50%         2.000000  \n",
       "75%         4.000000  \n",
       "max         4.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Descriptive Statistics\n",
    "\n",
    "Just by glancing at the above table, columns `Age`, `Breed1`, `Color 2` & `Color 3` standout especially.\n",
    "\n",
    "Because the `min` value in each of the above mentioned columns is `0`.\n",
    "\n",
    "* **`Age`** of $0$ years is an abnormal value\n",
    "    * This indicates that the value for age is missing\n",
    "    * Need to replace the $0$ with `None`\n",
    "\n",
    "```python\n",
    "# TODO: Create a quantitative Imputer to fill the missing `Age` value\n",
    "```\n",
    "\n",
    "* **`Breed1`** number $0$ is an abnormal value.\n",
    "\n",
    "    * `BreedID` for Dogs ranges from $1 - 241$\n",
    "    * `BreedID` for Cats ranges from $242 - 307$\n",
    "    * `Breed2` value of $0$ indicates the pet is pure breed\n",
    "\n",
    "```python\n",
    "# TODO: Create a categorical imputer (df[col].value_counts.index[0])\n",
    "\n",
    "# TODO: Make sure to impute dog and cat categories separately\n",
    "```\n",
    "\n",
    "* **`Color2`** & **`Color3`** has color $0$\n",
    "\n",
    "    * `ColorID` ranges from $1 - 7$\n",
    "      \n",
    "      \n",
    "| Color  \t| ColorID \t|\n",
    "|--------\t|---------\t|\n",
    "| Black  \t| $1$       |\n",
    "| Brown  \t| $2$       |\n",
    "| Golden \t| $3$      \t|\n",
    "| Yellow \t| $4$      \t|\n",
    "| Cream  \t| $5$      \t|\n",
    "| Gray   \t| $6$      \t|\n",
    "| White  \t| $7$      \t|\n",
    "\n",
    "```python\n",
    "# TODO: Create a categorical imputer (df[col].value_counts.index[0])\n",
    "\n",
    "# TODO: Make sure to impute dog and cat categories separately\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type                 0\n",
       "Age                179\n",
       "Breed1               5\n",
       "Breed2               0\n",
       "Gender               0\n",
       "Color1               0\n",
       "Color2            4471\n",
       "Color3           10604\n",
       "MaturitySize         0\n",
       "FurLength            0\n",
       "Vaccinated           0\n",
       "Dewormed             0\n",
       "Sterilized           0\n",
       "Health               0\n",
       "Quantity             0\n",
       "AdoptionSpeed        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the above columns with 0 with None\n",
    "def replace_with_None(value=None, col=None, df=None):\n",
    "    df[col] = df[col].map(lambda x: x if x != value else None)\n",
    "\n",
    "# Replacing Age: 0 => None\n",
    "replace_with_None(value=0, col='Age', df=df)\n",
    "\n",
    "# Replacing Breed1: 0 => None\n",
    "replace_with_None(value=0, col='Breed1', df=df)\n",
    "\n",
    "# Replacing Color2 and Color3: 0 => None\n",
    "replace_with_None(value=0, col='Color2', df=df)\n",
    "replace_with_None(value=0, col='Color3', df=df)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values per column\n",
    "* `Age` - $179$ missing values\n",
    "* `Color2` - $4471$ missing values\n",
    "* `Color3` - $10604$ missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost Data is 70.72633895818049%\n"
     ]
    }
   ],
   "source": [
    "lost_data = 100.0 - ((len(df) - 10604)/len(df))*100.0\n",
    "print(\"Lost Data is {}%\".format(lost_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we choose to remove the rows where `Color3` is $None$. Then we would essentially loose $72%$ of the data.\n",
    "\n",
    "Losing $72%$ of the data will prevent the model from learning more intricate patterns hidden in the data.\n",
    "\n",
    "Hence, instead of removing the rows that contain $None$, we shall impute the values for the missing rows using [`Imputer`](https://sklearn.org/modules/generated/sklearn.preprocessing.Imputer.html) class.\n",
    "\n",
    "The generic `Imputer` class does not however meet our requirements, hence we can implement a custom imputer class by subclassing from [`TransformerMixIn`](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html) as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "class CustomQuantitativeImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols=None, strategy='mean'):\n",
    "\n",
    "        if not cols:\n",
    "            raise ValueError(\"'{}' cannot be {}\".format('cols', None))\n",
    "\n",
    "        if not strategy:\n",
    "            raise ValueError(\"'{}' cannot be {}\".format('strategy', None))\n",
    "\n",
    "        if not isinstance(cols, list):\n",
    "            raise TypeError(\"'{}' should be of {}\".format('cols', list))\n",
    "\n",
    "        if not isinstance(strategy, str):\n",
    "            raise TypeError(\"'{}' should be of {}\".format('strategy', str))\n",
    "\n",
    "        self.cols = cols\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def _impute_null_with_strategy(self, col=None, X=None):\n",
    "\n",
    "        # Categorising the data into Dogs and Cats\n",
    "        dog_data = X[X['Type']==1]\n",
    "        cat_data = X[X['Type']==2]\n",
    "\n",
    "        _dog, _cat = None, None\n",
    "\n",
    "        # Finding per category Mean / Median         \n",
    "        if self.strategy == 'median':\n",
    "            _dog = dog_data[col].median()\n",
    "            _cat = cat_data[col].median()\n",
    "        else:\n",
    "            _dog = dog_data[col].mean()\n",
    "            _cat = cat_data[col].mean()\n",
    "        \n",
    "        # Finding the rows (indices) with missing values in a column\n",
    "        dog_missing_indices = dog_data[dog_data[col].isnull()].index\n",
    "        cat_missing_indices = cat_data[cat_data[col].isnull()].index\n",
    "\n",
    "        # Imputing the missing values in column(s) with Mean / Median value per category\n",
    "        X.loc[dog_missing_indices, col] = _dog\n",
    "        X.loc[cat_missing_indices, col] = _cat\n",
    "        \n",
    "        return X[col]\n",
    "\n",
    "    def transform(self, df):\n",
    "        X = df.copy()\n",
    "\n",
    "        # TODO: Impute the missing values using self.strategy in each column\n",
    "        for col in self.cols:\n",
    "            X[col] = self._impute_null_with_strategy(col=col, X=X)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "\n",
    "class CustomCategoricalImputer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self, cols=None):\n",
    "\n",
    "        if not cols:\n",
    "            raise ValueError(\"'{}' cannot be {}\".format('cols', cols))\n",
    "\n",
    "        if not isinstance(cols, list):\n",
    "            raise TypeError(\"'{}' should be of {}\".format('cols', list))\n",
    "\n",
    "        self.cols = cols\n",
    "    \n",
    "    def transform(self, df):\n",
    "        X = df.copy()\n",
    "        # TODO: find mean of dog and cat categories\n",
    "        # TODO: Impute the missing value of dog if the Type is 1 and viceversa\n",
    "        dog_data = df[df[type==1]]\n",
    "        cat_data = df[df[type==2]]\n",
    "\n",
    "        for col in self.cols:\n",
    "            pass\n",
    "\n",
    "        return X\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "imputer = Pipeline([('quant', CustomQuantitativeImputer(cols=['Age']))])\n",
    "df = imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type                 0\n",
       "Age                  0\n",
       "Breed1               5\n",
       "Breed2               0\n",
       "Gender               0\n",
       "Color1               0\n",
       "Color2            4471\n",
       "Color3           10604\n",
       "MaturitySize         0\n",
       "FurLength            0\n",
       "Vaccinated           0\n",
       "Dewormed             0\n",
       "Sterilized           0\n",
       "Health               0\n",
       "Quantity             0\n",
       "AdoptionSpeed        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adoption_speed = df['AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Fee and Quantity Columns\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "df[['Fee']] = min_max_scaler.fit_transform(df[['Fee']])\n",
    "df = df.drop(labels=['AdoptionSpeed'], axis=1)\n",
    "df.to_csv('./data/train/train_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = pd.read_csv('./data/train/train_scaled.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, adoption_speed, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy Score: {0:.2f}%\".format(accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "plot_importance(model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
